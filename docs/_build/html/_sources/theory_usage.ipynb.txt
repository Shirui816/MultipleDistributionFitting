{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory and Usage\n",
    "\n",
    "\n",
    "## Theory\n",
    "\n",
    "Our goal is to find optimized number of components in a mixture model. Assuming that a mixture of distributions are given as:\n",
    "\n",
    "$$\n",
    "f(x)=\\sum_i^na_ig_i(x;\\mathbf{\\theta}_i)\n",
    "$$\n",
    "\n",
    "That each $g_i(x;\\mathbf{\\theta}_i)$ is a distribution function with weigth $a_i$, $\\mathbf{\\theta}_i$ is the parameter vector. Usually, a mixture model data set can be fitted by arbitary number of components $n$, to supress overfitting, Akaike information criterion (AIC), Bayesian information criterion (BIC) and a modified AIC (AICc) is used for small sized samples to estimate the model and find out the most probable number of components $n$.\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Generate mixture models for fitting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. code-block:: python\n",
    "\n",
    "    from utils import n_func_mix, n_func_maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a n-fucntion mixture from a common base\n",
    "```python\n",
    "def n_func_maker(func: callable, n: int, known: list) -> callable:\n",
    "    r\"\"\"Make n-function mixture from a common base.\n",
    "    \n",
    "    Arguments:\n",
    "    func: base function, the signature must start with `x`.\n",
    "    n: desired number of components.\n",
    "    known: a list of $n\\times n_{\\text{func args}}$ variables.\n",
    "           None is for fitting variables and values for fixed variables.\n",
    "    \n",
    "    Returns:\n",
    "    mixture: callable.\n",
    "    \"\"\"\n",
    "```\n",
    "For example, suppose that a 2-component mixture is generated by the base fuction `f(x, a, b, c)` that the `a` variable of 2nd function is equal to 2, the `n_func_maker(f, 2, known=[None, None, None, 2, None, None])` generates a mixed function with signatures `x, a0, b0, c0, b1, c1`.\n",
    "\n",
    "#### Make mixture of functions\n",
    "```python\n",
    "def n_func_mix(funcs: list of callables) -> callable:\n",
    "    r\"\"\"Mixer for defining functions mixed by base function.\n",
    "\n",
    "    For scipy.optimize.curv_fit.\n",
    "\n",
    "    Arguments:\n",
    "    funcs: A list of callables, and signatures of\n",
    "           all functions must begin with `x`.\n",
    "\n",
    "    Returns: Function that mixed n base functions.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "### Fitting the generated models\n",
    "```python\n",
    "from utils import FitLSQ\n",
    "\n",
    "class FitLSQ():\n",
    "    def __init__(self, func: callable):\n",
    "    \n",
    "    def set_bounds(self, bounds: list, known: list) -> self:\n",
    "        r\"\"\"Set bounds for target function.\n",
    "\n",
    "        Arguments:\n",
    "        bounds: 2d-list for lower and upper bounds (lb, ub) for arguments\n",
    "                of base function. +/-np.inf for no bounds.\n",
    "        n: number of parameters ofl BASE functions.\n",
    "        known: Known parts in functions.\n",
    "        Returns:\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "    def set_p0(self, p0: list, known: list) -> self:\n",
    "        r\"\"\"Set initial values for fitting.\n",
    "\n",
    "        Arguments:\n",
    "        p0: tuple or list for initial parameters.\n",
    "        known: list for known components.\n",
    "\n",
    "        Returns:\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray, **kwargs) -> self:\n",
    "        r\"\"\"Fit the model.\n",
    "\n",
    "        Arguments:\n",
    "        x: np.array for x\n",
    "        y: np.array for y\n",
    "\n",
    "        Keyword Arguments:\n",
    "        kwargs that fits scipy.optimize.curve_fit\n",
    "\n",
    "        Returns:\n",
    "        self\n",
    "        \"\"\"\n",
    "```\n",
    "For example, `model.set_p0([0.1, 0.002, 3.7])` and `model.set_bound([[0, -np.inf, 1], [1,np.inf, 2]])` are for a mixture of consists of 3-argument base functions with initial guess of (0.1, 0.002, 3.7) for parameters and corresponding bounds are (0, 1), (-inf, inf) and (1, 2).\n",
    "\n",
    "**Warning:** `set_p0` and `set_bounds` are currently supported for the compoents in the mixture have same base function only.\n",
    "\n",
    "### Evaluate models.\n",
    "```python\n",
    "from utils import Evaluation\n",
    "\n",
    "class Evaluation():\n",
    "    def __init__(self, model: FitLSQ):\n",
    "        r\"\"\"Initialize with model.\n",
    "\n",
    "        Arguments:\n",
    "        model: a fit object\n",
    "        \"\"\"\n",
    "    \n",
    "    def aic(self, x: np.ndarray) -> np.ndarray:\n",
    "        r\"\"\"Calculate AIC.\n",
    "\n",
    "        Aho, K.; Derryberry, D.; Peterson, T. (2014), \"Model selection for\n",
    "        ecologists: the worldviews of AIC and BIC\", Ecology, 95: 631–636,\n",
    "        doi:10.1890/13-1452.1.\n",
    "\n",
    "        AIC = 2k - 2\\ln{\\hat{\\mathcal{L}}}, \\hat{\\mathcal{{L}}} is Likelihood.\n",
    "\n",
    "        Arguments:\n",
    "        samples: samples of (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "        aic: np.ndarray\n",
    "        \"\"\"\n",
    " \n",
    "    def bic(self, x: np.ndarray) -> np.ndarray:\n",
    "        r\"\"\"Calculate BIC.\n",
    "\n",
    "        Schwarz, Gideon E. (1978), \"Estimating the dimension of a model\",\n",
    "        Annals of Statistics, 6 (2): 461–464, doi:10.1214/aos/1176344136,\n",
    "        MR 0468014.\n",
    "\n",
    "        BIC = \\ln{N}k - 2\\ln{\\hat{\\mathcal{L}}}\n",
    "\n",
    "        Arguments:\n",
    "        samples: samples of (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "        bic: np.ndarray\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def aicc(self, x: np.ndarray) -> np.ndarray:\n",
    "        r\"\"\"Calculate AICc.\n",
    "\n",
    "        deLeeuw, J. (1992), \"Introduction to Akaike (1973) information theory\n",
    "        and an extension of the maximum likelihood principle\" (PDF),\n",
    "        in Kotz, S.; Johnson, N.L., Breakthroughs in Statistics I, Springer,\n",
    "        pp. 599–609.\n",
    "\n",
    "        AICc = AIC + \\frac{2k^2+2k}{N-k-1}\n",
    "\n",
    "        Arguments:\n",
    "        samples: samples of (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "        aicc: np.ndarray\n",
    "        \"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def make_sample(cls, n, x, pdf):\n",
    "        r\"\"\"Make random sample taken from x.\n",
    "\n",
    "        Arguments:\n",
    "        n: int, sample size\n",
    "        x: np.ndarray\n",
    "        pdf: np.ndarray\n",
    "\n",
    "        Returns:\n",
    "        sample\n",
    "        \"\"\"\n",
    "```\n",
    "\n",
    "`x` is a sample data set with shape of (n_samples, n_features), samples can be generated by `Evaluation.make_sample` from the fitting data `x` and `y` if the fitting object is the pdf function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
